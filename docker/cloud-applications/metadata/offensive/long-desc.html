<p class="clearfix">This classifier is a fine-tuned Roberta-base model using the <a href="https://simpletransformers.ai/">simpletransformers toolkit</a>. We use the <a href="https://sites.google.com/site/offensevalsharedtask/olid">OLIDv1 dataset from OffensEval 2019</a> as training data. This dataset contains tweets classified as offensive or non-offensive. </p>


<p><button class="btn btn-info" data-toggle="collapse" data-target="#ldAnnotationDetails"><i class="icon-info-sign icon-white"></i> Annotation details</button></p>

<div class="collapse clearfix" id="ldAnnotationDetails">
<table>
  <tr>
    <td colspan="2"><b>Default annotations</b></td>
  </tr>
  <tr>
    <td><tt>:OffensiveLanguage</tt></td>
    <td>an annotation which spans the entire document and has the following features:
      <ul>
        <li><tt>isOffensive</tt>, true if the classifier has determined the text is offensive, false otherwise</li>
	<li><tt>probability</tt>, the probability with which the classifier assigned the isOffensive label</li>
      </ul>
    </td>
  </tr>
</table>
</div>
